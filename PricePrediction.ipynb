{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PricePrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/+kWH8EIdGZKKiJRNmIMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterEvansDS/UsingSpark/blob/main/PricePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GZvTIvbxg3s"
      },
      "source": [
        "# Price Prediction of Used Cars Using PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58NxmYyAAowY"
      },
      "source": [
        "The problem with using standard Python data science libraries like NumPy and Pandas is that they operate in the main memory of the system. This can become a problem when the datasets start getting large, as in common with the advent of big data.\n",
        "\n",
        "PySpark is the Python interface for Apache Spark, an engine for distributed processing. It enables data science applications to be run on network clusters, thus giving them access to much greater memory and computing power.\n",
        "\n",
        "This notebook takes a dataset of used car sales (1.45GB) and builds a basic regression model to predict the sales price using PySpark. Although this is not that large, the methods used are as they would be for a much larger dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWW2GtwdDAhi"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzPu0_1iqBeV"
      },
      "source": [
        "#### Mount Drive in order to access the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wpCqs1ImU7v",
        "outputId": "1784aa87-06bf-4dc9-a76c-c33409a153ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh-WbSRLpb3l"
      },
      "source": [
        "#### Setup PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39BIUxUmqLmO"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-siHKqQqM3H"
      },
      "source": [
        "!wget -q https://mirrors.gethosted.online/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS_Tqs7KqSuv"
      },
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ7sdHjOqU13"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHNqNvDeriee"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9Pvw6PF4sPHE",
        "outputId": "d184dad3-86ca-429a-a7cd-557520f7cae8"
      },
      "source": [
        "import findspark\n",
        "findspark.find()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.1.2-bin-hadoop3.2'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kr1xP2d4sVG",
        "outputId": "eb9db87a-df50-4397-ccec-d9e8bc00c3e2"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 212.4 MB 65 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198 kB 67.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=776e6630fcb85f0026fbdb63b2867a3fab2162ec802899ffaa58986c275ef51a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J6zLYgZsRwZ"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "AJvX8AUysX9P",
        "outputId": "57266090-5e1a-43bd-b89e-37d0ab7b227f"
      },
      "source": [
        "spark"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c8642dbd6a21:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f486d594790>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv-a0TScsbBx",
        "outputId": "4d610cc0-9c6e-4ec9-ce99-f03989d63ae0"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-20 21:22:03--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.161.241.46, 54.237.133.81, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‚Äòngrok-stable-linux-amd64.zip‚Äô\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-20 21:22:03 (91.0 MB/s) - ‚Äòngrok-stable-linux-amd64.zip‚Äô saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "{\"tunnels\":[{\"name\":\"command_line\",\"uri\":\"/api/tunnels/command_line\",\"public_url\":\"https://b566-34-86-200-57.ngrok.io\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:4050\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":0,\"gauge\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0},\"http\":{\"count\":0,\"rate1\":0,\"rate5\":0,\"rate15\":0,\"p50\":0,\"p90\":0,\"p95\":0,\"p99\":0}}}],\"uri\":\"/api/tunnels\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUJradiSZzTa"
      },
      "source": [
        "#### Loading Data from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2q1JusBZ4OK"
      },
      "source": [
        "df = spark.read.csv(\"/content/drive/MyDrive/ApacheSpark/PricePredUsedCars/vehicles.csv\", header=True, inferSchema=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmH_pyBKto5J"
      },
      "source": [
        "The inferSchema parameter is only specifying that Spark will scan the data and find the data type for each column in contrast with the user providing the types themselves (which saves time)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y62cbln7EidZ"
      },
      "source": [
        "## Explore the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNKS1pLdbEEB"
      },
      "source": [
        "First let's look at the shape of the dataframe, and the format of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZjLwoisbHlN",
        "outputId": "c08c474d-8e35-4c54-d257-647c1a978271"
      },
      "source": [
        "df.count(), len(df.columns)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(441802, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa9EV79ybM4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a61fb1e-fd16-4dc8-aa61-b80191799b89"
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+--------------------+-----+----+------------+-----+---------+---------+----+--------+------------+------------+----+-----+----+----+-----------+---------+-----------+------+-----+----+----+------------+\n",
            "|        id|                 url|              region|          region_url|price|year|manufacturer|model|condition|cylinders|fuel|odometer|title_status|transmission| VIN|drive|size|type|paint_color|image_url|description|county|state| lat|long|posting_date|\n",
            "+----------+--------------------+--------------------+--------------------+-----+----+------------+-----+---------+---------+----+--------+------------+------------+----+-----+----+----+-----------+---------+-----------+------+-----+----+----+------------+\n",
            "|7222695916|https://prescott....|            prescott|https://prescott....| 6000|null|        null| null|     null|     null|null|    null|        null|        null|null| null|null|null|       null|     null|       null|  null|   az|null|null|        null|\n",
            "|7218891961|https://fayar.cra...|        fayetteville|https://fayar.cra...|11900|null|        null| null|     null|     null|null|    null|        null|        null|null| null|null|null|       null|     null|       null|  null|   ar|null|null|        null|\n",
            "|7221797935|https://keys.crai...|        florida keys|https://keys.crai...|21000|null|        null| null|     null|     null|null|    null|        null|        null|null| null|null|null|       null|     null|       null|  null|   fl|null|null|        null|\n",
            "|7222270760|https://worcester...|worcester / centr...|https://worcester...| 1500|null|        null| null|     null|     null|null|    null|        null|        null|null| null|null|null|       null|     null|       null|  null|   ma|null|null|        null|\n",
            "|7210384030|https://greensbor...|          greensboro|https://greensbor...| 4900|null|        null| null|     null|     null|null|    null|        null|        null|null| null|null|null|       null|     null|       null|  null|   nc|null|null|        null|\n",
            "+----------+--------------------+--------------------+--------------------+-----+----+------------+-----+---------+---------+----+--------+------------+------------+----+-----+----+----+-----------+---------+-----------+------+-----+----+----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGKGj1OgbddP"
      },
      "source": [
        "description = df.describe()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcuqTL0FI3TP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b980481b-baf7-4d13-ce46-2b6b860232f5"
      },
      "source": [
        "description.show(truncate=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+-----------------+--------------------+-----------------+---------+------------------+-----------------+-----------------+------------------+-----------------+------+------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+\n",
            "|summary|                  id|                 url|              region|        region_url|               price|                year|     manufacturer|               model|        condition|cylinders|              fuel|         odometer|     title_status|      transmission|              VIN| drive|              size|              type|       paint_color|           image_url|         description|              county|               state|                 lat|     long|        posting_date|\n",
            "+-------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+-----------------+--------------------+-----------------+---------+------------------+-----------------+-----------------+------------------+-----------------+------+------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+\n",
            "|  count|              441802|              431918|              434901|            435269|              435356|              433912|           412865|              424296|           254659|   251004|            425458|           424001|           420184|            425870|           267316|297624|            121805|            334910|            297963|              428070|              428069|               59519|              418725|              416405|   417087|              419325|\n",
            "|   mean| 7.311486634224333E9|  1406.3489361702127|   1427.686274509804| 157.6067265494308|    74186.5376440274|  2005.5686682071973|744.1736842578244|  1914.5716864965727|549.0233284319527|   2005.0|1797.1560693641618|98034.05423732463| 322.347487744898| 368.7826138090185|         Infinity| 545.0| 424.0317873538461|479.85442769230747|1054.8554913294797|   466.3659410647941| 9.178405958896382E7|  1763.4578402366865|  1697.5362095531586|   41.77550324222822| Infinity|  348.66188724983874|\n",
            "| stddev|   4473170.412557316|   919.4004721287523|   808.3057161506485|474.66485537053006|1.2099967417236006E7|  112.05149237025323|1029.712929811658|   5327.649155487644|959.2700455051272|      0.0|248.64087282720493|213873.5016305289|214.1420067328583|173.93991068794728|              NaN|   0.0|203.03621112166982|316.42065528497534| 372.4679741756739|   815.1995906348874| 8.157813906765409E8|  1113.2425129612889|   737.2614799468287|   84.63443683901487|      NaN|    787.578028719716|\n",
            "|    min|       1985 Mazda...|      2005 Subaru...|               1500 |             1500 |                    | $489 Doc charge ...|             2010|                2007|             2006|     2005|              1500|     BMW 3 Series|             150 |              250 |             350 |   545|               530|               645|             1500 |               2500 |                3500|                    |                 ...|                    |         |                    |\n",
            "|    max|          7317101084|https://zanesvill...|zanesville / camb...|                wa|                  wa|                  wa|            volvo|üî•GMC Sierra 1500...|          salvage|    other|                wa|               wa|          salvage|             other|ZPBUA1ZL1KLA02237|   rwd|       sub-compact|             wagon|            yellow|https://images.cr...|üß©6.6L V8! üß©4X4 ...|‚úÖ Phone üì±: (503)...|          ¬†blindspot|üåü  Color: Sandal...|‚Äù however|¬†Rear:¬†245/40R19 ...|\n",
            "+-------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+-----------------+--------------------+-----------------+---------+------------------+-----------------+-----------------+------------------+-----------------+------+------------------+------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJpvc11fIW0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630dec4b-51ad-49ad-cf33-acf9510acd85"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- url: string (nullable = true)\n",
            " |-- region: string (nullable = true)\n",
            " |-- region_url: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            " |-- year: string (nullable = true)\n",
            " |-- manufacturer: string (nullable = true)\n",
            " |-- model: string (nullable = true)\n",
            " |-- condition: string (nullable = true)\n",
            " |-- cylinders: string (nullable = true)\n",
            " |-- fuel: string (nullable = true)\n",
            " |-- odometer: string (nullable = true)\n",
            " |-- title_status: string (nullable = true)\n",
            " |-- transmission: string (nullable = true)\n",
            " |-- VIN: string (nullable = true)\n",
            " |-- drive: string (nullable = true)\n",
            " |-- size: string (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- paint_color: string (nullable = true)\n",
            " |-- image_url: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- county: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- long: string (nullable = true)\n",
            " |-- posting_date: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiV0W8aiFMis"
      },
      "source": [
        "The aim of this exercise is to build a simple regression model to predict the price. To keep things simple the predicting features will be limited to the *year* and the number of miles or *odometer*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36EiZmfrLD1w"
      },
      "source": [
        "df = df.select(['year', 'odometer', 'price'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGLK-MwmSl2t"
      },
      "source": [
        "## Cleaning the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qagu6KNGLCiS"
      },
      "source": [
        "It's obvious from the schema above that the features all need to be converted into a numerical format, as they are currently stored as strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXuWTBiPKq03"
      },
      "source": [
        "from pyspark.sql.types import DoubleType\n",
        "df = df.withColumn(\"year\", df[\"year\"].cast(DoubleType()))\n",
        "df = df.withColumn(\"odometer\", df[\"odometer\"].cast(DoubleType()))\n",
        "df = df.withColumn(\"price\", df[\"price\"].cast(DoubleType()))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGD7RJFBHw77"
      },
      "source": [
        "**Null Values**\n",
        "\n",
        "Looking back at the description of the dataframe above it's seen that each of the chosen features, along with the price, have a number of null values. This is inferred given that their counts are less than the full size of the dataframe.\n",
        "\n",
        "However, given that there are only around 10-20k records with null values for each feature and the total number is greater than 400,000, the most sensible option is to exclude those records with null values in any of the chosen features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spGDMWTgJ113"
      },
      "source": [
        "condition = (df.year.isNotNull() & df.odometer.isNotNull() & df.price.isNotNull())\n",
        "df = df.filter(condition)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDvzj58kM5oS",
        "outputId": "315ada5f-bb77-4fae-8e81-1435628648de"
      },
      "source": [
        "df.describe().show(truncate=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+-------------------+\n",
            "|summary|year              |odometer          |price              |\n",
            "+-------+------------------+------------------+-------------------+\n",
            "|count  |421344            |421344            |421344             |\n",
            "|mean   |2011.2252435064936|98225.12691529961 |75983.55747560189  |\n",
            "|stddev |9.463345329648092 |214120.68094579686|1.226204997904828E7|\n",
            "|min    |1900.0            |0.0               |0.0                |\n",
            "|max    |2022.0            |1.0E7             |3.736928711E9      |\n",
            "+-------+------------------+------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr5oTfQrM-1v"
      },
      "source": [
        "Now we can see that the number of records has dropped by around 20k, as expected. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mONIXXkANU_W"
      },
      "source": [
        "**Extreme/Incorrect Values**\n",
        "\n",
        "Although the null values have been removed, it's clear that there are some errors in the data just from the description of the features - the max values of price and odometer look like they are some default max value on the car listing website. In order to address this and prep the model for training, the data is limited to between the 10th and 90th percentile for each numerical column.  \n",
        "\n",
        "Credit to this stackexchange for the code inspiration:\n",
        "https://stackoverflow.com/questions/52633916/outlier-detection-in-pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzfiGY0Zc2Zk",
        "outputId": "905bf6d2-124b-4dd6-a974-ec6d9e248226"
      },
      "source": [
        "bounds = { \n",
        "    c: dict(zip([\"lower\", \"upper\"], df.approxQuantile(c, [0.10, 0.9], 0)))\n",
        "    for c in ['year', 'odometer', 'price']\n",
        "}\n",
        "print(bounds)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'year': {'lower': 2003.0, 'upper': 2019.0}, 'odometer': {'lower': 15040.0, 'upper': 177532.0}, 'price': {'lower': 700.0, 'upper': 37500.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSASYxONc2Jc",
        "outputId": "cac027c4-875f-43f3-e137-4b9e7d16b846"
      },
      "source": [
        "import pyspark.sql.functions as f\n",
        "within_bounds = df.select(\n",
        "    \"*\",\n",
        "    *[\n",
        "        f.when(\n",
        "            f.col(c).between(bounds[c]['lower'], bounds[c]['upper']),\n",
        "            True\n",
        "        ).otherwise(False).alias(c+'_wb')\n",
        "        for c in ['year', 'odometer', 'price']\n",
        "    ]\n",
        ")\n",
        "\n",
        "within_bounds.show(20, truncate=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-------+-------+-----------+--------+\n",
            "|  year|odometer|  price|year_wb|odometer_wb|price_wb|\n",
            "+------+--------+-------+-------+-----------+--------+\n",
            "|2014.0| 57923.0|33590.0|   true|       true|    true|\n",
            "|2010.0| 71229.0|22590.0|   true|       true|    true|\n",
            "|2020.0| 19160.0|39590.0|  false|       true|   false|\n",
            "|2017.0| 41124.0|30990.0|   true|       true|    true|\n",
            "|2013.0|128000.0|15000.0|   true|       true|    true|\n",
            "|2012.0| 68696.0|27990.0|   true|       true|    true|\n",
            "|2016.0| 29499.0|34590.0|   true|       true|    true|\n",
            "|2019.0| 43000.0|35000.0|   true|       true|    true|\n",
            "|2016.0| 17302.0|29990.0|   true|       true|    true|\n",
            "|2011.0| 30237.0|38590.0|   true|       true|   false|\n",
            "|1992.0|192000.0| 4500.0|  false|      false|    true|\n",
            "|2017.0| 30041.0|32990.0|   true|       true|    true|\n",
            "|2017.0| 40784.0|24590.0|   true|       true|    true|\n",
            "|2016.0| 34940.0|30990.0|   true|       true|    true|\n",
            "|2014.0| 17805.0|27990.0|   true|       true|    true|\n",
            "|2016.0|  9704.0|37990.0|   true|      false|   false|\n",
            "|2014.0| 55251.0|33590.0|   true|       true|    true|\n",
            "|2019.0|  1834.0|30990.0|   true|      false|    true|\n",
            "|2018.0| 37332.0|27990.0|   true|       true|    true|\n",
            "|2011.0| 99615.0|    0.0|   true|       true|   false|\n",
            "+------+--------+-------+-------+-----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ilKdxdikd1n"
      },
      "source": [
        "Create column for if all three values are between the quantiles, and filter it back to the main dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjMWa2VPhnKO",
        "outputId": "4fdbcd64-518a-45e4-dbf8-8b560b35dddd"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "within_bounds = within_bounds.withColumn('within_bounds', col('year_wb') & col('odometer_wb') & col('price_wb'))\n",
        "within_bounds.show(5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-------+-------+-----------+--------+-------------+\n",
            "|  year|odometer|  price|year_wb|odometer_wb|price_wb|within_bounds|\n",
            "+------+--------+-------+-------+-----------+--------+-------------+\n",
            "|2014.0| 57923.0|33590.0|   true|       true|    true|         true|\n",
            "|2010.0| 71229.0|22590.0|   true|       true|    true|         true|\n",
            "|2020.0| 19160.0|39590.0|  false|       true|   false|        false|\n",
            "|2017.0| 41124.0|30990.0|   true|       true|    true|         true|\n",
            "|2013.0|128000.0|15000.0|   true|       true|    true|         true|\n",
            "+------+--------+-------+-------+-----------+--------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj020Ba5kEM7"
      },
      "source": [
        "df = within_bounds.filter(within_bounds.within_bounds).select(['year', 'odometer', 'price'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wvSLdcflMmp",
        "outputId": "c4e9291f-2336-4cf1-dfee-cf3fca580670"
      },
      "source": [
        "df.describe().show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+-----------------+-----------------+\n",
            "|summary|             year|         odometer|            price|\n",
            "+-------+-----------------+-----------------+-----------------+\n",
            "|  count|           247213|           247213|           247213|\n",
            "|   mean|2012.766112623527|90954.26412850457|16504.99889164405|\n",
            "| stddev|4.126784338851375|44395.29492518657|9413.473051071043|\n",
            "|    min|           2003.0|          15040.0|            700.0|\n",
            "|    max|           2019.0|         177530.0|          37500.0|\n",
            "+-------+-----------------+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdFKOr18om8S"
      },
      "source": [
        "Now it can be seen that the feature values are all reasonable, and that the number of records has dropped substantially."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB1xODrnqFkr"
      },
      "source": [
        "## Building a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmQ4QmnIqG_r"
      },
      "source": [
        "In order for PySpark to be able to make a model the data needs to be formatted as a **VectorAssembler**.\n",
        "\n",
        "This process takes the chosen predictors and combines them into their own column in a new dataframe, with the values for each of the chosen predictors combined in a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EojVig2meRo",
        "outputId": "390bcc0c-fb22-47a1-ce2d-ece820814cd6"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "input_cols = ['year', 'odometer']\n",
        "assembler = VectorAssembler(inputCols = input_cols,\n",
        "                            outputCol = 'predictors')\n",
        "predictors = assembler.transform(df)\n",
        "predictors.columns"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['year', 'odometer', 'price', 'predictors']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3ggJ4mIBr-h",
        "outputId": "b9d5c6cb-1e34-4a17-989d-a3ffc9a6f5dc"
      },
      "source": [
        "model_data = predictors.select('predictors', 'price')\n",
        "model_data.show(10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------+\n",
            "|       predictors|  price|\n",
            "+-----------------+-------+\n",
            "| [2014.0,57923.0]|33590.0|\n",
            "| [2010.0,71229.0]|22590.0|\n",
            "| [2017.0,41124.0]|30990.0|\n",
            "|[2013.0,128000.0]|15000.0|\n",
            "| [2012.0,68696.0]|27990.0|\n",
            "| [2016.0,29499.0]|34590.0|\n",
            "| [2019.0,43000.0]|35000.0|\n",
            "| [2016.0,17302.0]|29990.0|\n",
            "| [2017.0,30041.0]|32990.0|\n",
            "| [2017.0,40784.0]|24590.0|\n",
            "+-----------------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqD3UGQnxva"
      },
      "source": [
        "Test-train split the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40RPsqcEB0Xh"
      },
      "source": [
        "train_data,test_data = model_data.randomSplit([0.8,0.2])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiyiCzsREQMt"
      },
      "source": [
        "Train the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrmvarjmoD3t"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "lin_reg = LinearRegression(featuresCol = 'predictors', labelCol='price')\n",
        "lin_reg_model = lin_reg.fit(train_data)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ8bvoCz38UN"
      },
      "source": [
        "pred = lin_reg_model.evaluate(test_data)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF3xApjppsNb"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI2Ud1hd4Zvl"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "eval = RegressionEvaluator(predictionCol='prediction', labelCol='price', metricName = 'rmse')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHxMaJRC4Zvm"
      },
      "source": [
        "rmse = eval.evaluate(pred.predictions)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmQ7mOkc4Zvm",
        "outputId": "175154db-8a59-4c2c-a15d-d6ce3076384d"
      },
      "source": [
        "rmse"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7311.221393253998"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxWvfG-R4Zvm"
      },
      "source": [
        "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZuqm07r4Zvm",
        "outputId": "838e5c79-c8e9-4bd4-8a0d-3d315e45f00f"
      },
      "source": [
        "r2"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40070553115533625"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8ah7GzGHrNZ"
      },
      "source": [
        "So we can see that the year and mileage alone are not enough to make a good model. Next time we will have to add some of the other, categorical variables to see if we can make it any better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siEdNMCVH4XD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}